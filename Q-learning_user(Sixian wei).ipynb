{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6278c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f09db3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           0\n",
      "business_id       0\n",
      "stars_x           0\n",
      "average_stars     0\n",
      "review_count_x    0\n",
      "fans              0\n",
      "categories        1\n",
      "stars_y           0\n",
      "review_count_y    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read a larger number of review records\n",
    "review = pd.read_json('./data/yelp_academic_dataset_review.json', lines=True, nrows=100000)\n",
    "\n",
    "# Get the user_id and business_id that appear in the reviews\n",
    "valid_user_ids = set(review['user_id'])\n",
    "valid_business_ids = set(review['business_id'])\n",
    "\n",
    "# Step 2: Extract matched user data based on review\n",
    "user_iter = pd.read_json('./data/yelp_academic_dataset_user.json', lines=True, chunksize=100000)\n",
    "user_chunks = []\n",
    "for chunk in user_iter:\n",
    "    user_chunks.append(chunk[chunk['user_id'].isin(valid_user_ids)])\n",
    "user = pd.concat(user_chunks, ignore_index=True)\n",
    "\n",
    "# Step 3: Extract matched business data based on review\n",
    "business_iter = pd.read_json('./data/yelp_academic_dataset_business.json', lines=True, chunksize=100000)\n",
    "business_chunks = []\n",
    "for chunk in business_iter:\n",
    "    business_chunks.append(chunk[chunk['business_id'].isin(valid_business_ids)])\n",
    "business = pd.concat(business_chunks, ignore_index=True)\n",
    "\n",
    "# Final step: merge all datasets\n",
    "business_df = business[['business_id', 'categories', 'stars', 'review_count']]\n",
    "user_df = user[['user_id', 'average_stars', 'review_count', 'fans']]\n",
    "review_df = review[['user_id', 'business_id', 'stars']]\n",
    "\n",
    "data = review_df \\\n",
    "    .merge(user_df, on='user_id', how='left') \\\n",
    "    .merge(business_df, on='business_id', how='left')\n",
    "\n",
    "# Check for any NaN values after merging\n",
    "print(data.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28219fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct user state: (average_stars, review_count, fans)\n",
    "data['state'] = list(zip(data['average_stars'], data['review_count_x'], data['fans']))\n",
    "\n",
    "# Construct action (business): use business_id\n",
    "data['action'] = data['business_id']\n",
    "\n",
    "# Define reward: use the user's rating of the business as the reward\n",
    "data['reward'] = data['stars_x']  # i.e., the user's rating\n",
    "\n",
    "# Convert state from tuple to string for encoding\n",
    "data['state_str'] = data['state'].apply(lambda x: '_'.join(map(str, x)))\n",
    "\n",
    "# Encode states and actions\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "state_encoder = LabelEncoder()\n",
    "data['state_enc'] = state_encoder.fit_transform(data['state_str'])\n",
    "\n",
    "action_encoder = LabelEncoder()\n",
    "data['action_enc'] = action_encoder.fit_transform(data['action'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b6b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Q-learning 训练完成！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "num_states = data['state_enc'].nunique()\n",
    "num_actions = data['action_enc'].nunique()\n",
    "Q = np.zeros((num_states, num_actions))  # Initialize Q-table\n",
    "\n",
    "# Q-learning parameters\n",
    "alpha = 0.1      # learning rate\n",
    "gamma = 0.9      # discount factor\n",
    "epsilon = 0.1    # exploration rate\n",
    "\n",
    "# Extract columns for training sequences\n",
    "states = data['state_enc'].values\n",
    "actions = data['action_enc'].values\n",
    "rewards = data['reward'].values\n",
    "\n",
    "# Train Q-learning algorithm\n",
    "for epoch in range(10):  # number of training iterations\n",
    "    for i in range(len(data) - 1):\n",
    "        s = states[i]\n",
    "        a = actions[i]\n",
    "        r = rewards[i]\n",
    "        s_next = states[i + 1]\n",
    "\n",
    "        # ε-greedy policy for action selection\n",
    "        if random.random() < epsilon:\n",
    "            a_next = random.randint(0, num_actions - 1)  # explore\n",
    "        else:\n",
    "            a_next = np.argmax(Q[s_next])  # exploit\n",
    "\n",
    "        # Q-value update\n",
    "        Q[s, a] += alpha * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "print(\"✅ Q-learning training completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106dbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_state, top_k=5):\n",
    "    user_state_str = '_'.join(map(str, user_state))\n",
    "    state_enc = state_encoder.transform([user_state_str])[0]\n",
    "    \n",
    "    top_actions = np.argsort(Q[state_enc])[::-1][:top_k]\n",
    "    recommended_ids = action_encoder.inverse_transform(top_actions)\n",
    "\n",
    "    recommended_business = business[business['business_id'].isin(recommended_ids)]\n",
    "    recommended_business = recommended_business.set_index('business_id').loc[recommended_ids].reset_index()\n",
    "\n",
    "    return recommended_business[['business_id', 'name', 'categories', 'stars', 'city']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6252e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5: 0.2286\n",
      "Recall@5: 0.8052\n",
      "F1-Score@5: 0.3362\n"
     ]
    }
   ],
   "source": [
    "def evaluate_precision_recall_f1(user_states, top_k=5, rating_threshold=4):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for user_state in user_states:\n",
    "        # Get top-k recommended businesses for the given user state\n",
    "        recommendations = recommend(user_state, top_k)['business_id'].tolist()\n",
    "\n",
    "        # Try to find the corresponding user ID from the state\n",
    "        try:\n",
    "            user_id = data[data['state'] == user_state].iloc[0]['user_id']\n",
    "        except:\n",
    "            continue  # Skip if no matching user found\n",
    "\n",
    "        # Ground truth: businesses the user actually liked (rating ≥ threshold)\n",
    "        true_likes = set(data[(data['user_id'] == user_id) & (data['reward'] >= rating_threshold)]['business_id'])\n",
    "        if not true_likes:\n",
    "            continue  # Skip if no liked businesses\n",
    "\n",
    "        # Compute hits (recommended businesses that were actually liked)\n",
    "        hits = set(recommendations) & true_likes\n",
    "        precision = len(hits) / top_k\n",
    "        recall = len(hits) / len(true_likes)\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    # Compute average scores\n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Example evaluation: take first 100 user states for testing\n",
    "sample_user_states = data['state'].unique()[:100]\n",
    "precision, recall, f1 = evaluate_precision_recall_f1(sample_user_states)\n",
    "\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1-Score@5: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33e95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
