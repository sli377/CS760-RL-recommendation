{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline_rl_slateq.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load train/test data\n",
    "# -----------------------------\n",
    "def read_jsonl(path):\n",
    "    return pd.read_json(path, lines=True)\n",
    "\n",
    "train_users      = read_jsonl('train_users.jsonl')\n",
    "train_businesses = read_jsonl('train_businesses.jsonl')\n",
    "train_reviews    = read_jsonl('train_reviews.jsonl').sort_values(['user_id','date']).reset_index(drop=True)\n",
    "\n",
    "test_users       = read_jsonl('test_users.jsonl')\n",
    "test_businesses  = read_jsonl('test_businesses.jsonl')\n",
    "test_reviews     = read_jsonl('test_reviews.jsonl').sort_values(['user_id','date']).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Preprocessing - categories vocabulary & fans_count\n",
    "# -----------------------------\n",
    "all_categories = set()\n",
    "for cats in train_businesses['categories'].dropna():\n",
    "    for c in cats.split(','):\n",
    "        all_categories.add(c.strip())\n",
    "all_categories = sorted(all_categories)\n",
    "cat2idx = {c:i for i,c in enumerate(all_categories)}\n",
    "\n",
    "def parse_fans(x):\n",
    "    if isinstance(x, str):\n",
    "        return len(x.split(','))\n",
    "    elif isinstance(x, list):\n",
    "        return len(x)\n",
    "    return 0\n",
    "\n",
    "for df in [train_users, test_users]:\n",
    "    df['fans_count'] = df['fans'].apply(parse_fans)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature extraction\n",
    "# -----------------------------\n",
    "def extract_user_feat(row):\n",
    "    return np.array([row['average_stars'],\n",
    "                     row['review_count'],\n",
    "                     row['fans_count']], dtype=np.float32)\n",
    "\n",
    "def extract_biz_feat(row):\n",
    "    base = [row['stars'], row['review_count']]\n",
    "    multi_hot = np.zeros(len(all_categories), dtype=np.float32)\n",
    "    if pd.notna(row['categories']):\n",
    "        for c in row['categories'].split(','):\n",
    "            idx = cat2idx.get(c.strip())\n",
    "            if idx is not None:\n",
    "                multi_hot[idx] = 1.0\n",
    "    return np.concatenate([np.array(base, dtype=np.float32), multi_hot])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Construct transitions\n",
    "# -----------------------------\n",
    "def build_transitions(reviews_df, users_df, biz_df):\n",
    "    users_idx = users_df.set_index('user_id')\n",
    "    biz_idx   = biz_df.set_index('business_id')\n",
    "    trans = []\n",
    "    for uid, grp in reviews_df.groupby('user_id', sort=False):\n",
    "        grp = grp.reset_index(drop=True)\n",
    "        if len(grp) < 2: continue\n",
    "        for i in range(len(grp)-1):\n",
    "            cur, nxt = grp.loc[i], grp.loc[i+1]\n",
    "            u_feat = extract_user_feat(users_idx.loc[uid])\n",
    "            b_feat = extract_biz_feat(biz_idx.loc[cur['business_id']])\n",
    "            u_feat_next = u_feat  # User features unchanged\n",
    "            b_feat_next = extract_biz_feat(biz_idx.loc[nxt['business_id']])\n",
    "            s  = np.concatenate([u_feat, b_feat])\n",
    "            a  = b_feat.copy()\n",
    "            r  = 1.0 if cur['stars'] >= 4 else 0.0\n",
    "            s2 = np.concatenate([u_feat_next, b_feat_next])\n",
    "            trans.append((s, a, r, s2))\n",
    "    return trans\n",
    "\n",
    "train_trans = build_transitions(train_reviews, train_users, train_businesses)\n",
    "test_trans  = build_transitions(test_reviews, test_users, test_businesses)\n",
    "print(f\"Train transitions: {len(train_trans)}  Test transitions: {len(test_trans)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. PyTorch Dataset\n",
    "# -----------------------------\n",
    "class TransDataset(Dataset):\n",
    "    def __init__(self, transitions):\n",
    "        self.data = transitions\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        s, a, r, s2 = self.data[i]\n",
    "        return (torch.from_numpy(s),\n",
    "                torch.from_numpy(a),\n",
    "                torch.tensor(r, dtype=torch.float32),\n",
    "                torch.from_numpy(s2))\n",
    "\n",
    "train_loader = DataLoader(TransDataset(train_trans), batch_size=256, shuffle=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Define Q-network\n",
    "# -----------------------------\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim+action_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, s, a):\n",
    "        x = torch.cat([s, a], dim=1)\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "user_dim = 3\n",
    "biz_dim  = 2 + len(all_categories)\n",
    "state_dim  = user_dim + biz_dim\n",
    "action_dim = biz_dim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "Q     = QNet(state_dim, action_dim).to(device)\n",
    "Q_tar = QNet(state_dim, action_dim).to(device)\n",
    "Q_tar.load_state_dict(Q.state_dict())\n",
    "opt = optim.Adam(Q.parameters(), lr=1e-3)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. SlateQ (SARSA-TS) training\n",
    "# -----------------------------\n",
    "gamma = 0.99\n",
    "tau   = 0.005  # Soft update\n",
    "K     = 10     # slate size\n",
    "\n",
    "cand_feats = torch.from_numpy(\n",
    "    np.stack([extract_biz_feat(row) for _, row in test_businesses.set_index('business_id').iterrows()])\n",
    ").to(device)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for s, a, r, s2 in train_loader:\n",
    "        s, a, r, s2 = s.to(device), a.to(device), r.to(device), s2.to(device)\n",
    "\n",
    "        q = Q(s, a)\n",
    "\n",
    "        ss = s2[:, :user_dim].unsqueeze(1).repeat(1, len(cand_feats), 1)\n",
    "        feats = cand_feats.unsqueeze(0).repeat(ss.size(0), 1, 1)\n",
    "        inp = torch.cat([ss, feats], dim=2).view(-1, state_dim)\n",
    "        qs2 = Q_tar(inp, feats.view(-1, biz_dim)).view(-1, len(cand_feats))\n",
    "        topk_vals, _ = torch.topk(qs2, K, dim=1)\n",
    "        q_next = topk_vals.mean(dim=1)\n",
    "\n",
    "        y = r + gamma * q_next.detach()\n",
    "\n",
    "        loss = nn.MSELoss()(q, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        for p, pt in zip(Q.parameters(), Q_tar.parameters()):\n",
    "            pt.data.copy_(tau*p.data + (1-tau)*pt.data)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}  loss={total_loss/len(train_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
