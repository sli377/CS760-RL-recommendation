{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a49e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import SpectralBiclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eec8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_first_n_json_objects(file_path, n):\n",
    "    \"\"\"\n",
    "    Efficiently reads the first `n` JSON objects from a large JSON array.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    obj = ''\n",
    "    depth = 0\n",
    "    started = False\n",
    "    count = 0\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        while True:\n",
    "            char = f.read(1)\n",
    "            if not char:\n",
    "                break\n",
    "\n",
    "            if char == '{':\n",
    "                depth += 1\n",
    "                started = True\n",
    "\n",
    "            if started:\n",
    "                obj += char\n",
    "\n",
    "            if char == '}':\n",
    "                depth -= 1\n",
    "                if depth == 0 and started:\n",
    "                    try:\n",
    "                        records.append(json.loads(obj))\n",
    "                        count += 1\n",
    "                        if count >= n:\n",
    "                            break\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                    obj = ''\n",
    "                    started = False\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9764fa62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load first 100000 entries efficiently\n",
    "subset = stream_first_n_json_objects(\"rl_dataset_train.json\", 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f75e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'state', 'action', 'action_time_segment', 'user_profile',\n",
      "       'business_checkin', 'business_categories', 'reward', 'next_state'],\n",
      "      dtype='object')\n",
      "                  user_id                                              state  \\\n",
      "0  mh_-eMZ6K5RLWhZyISBhwA  [{'business_id': 'WL-0PLW5IzdnyUHGmiOrgQ', 'st...   \n",
      "1  mh_-eMZ6K5RLWhZyISBhwA  [{'business_id': 'gpYBhnTk4KzvvH83TsZiQg', 'st...   \n",
      "2  mh_-eMZ6K5RLWhZyISBhwA  [{'business_id': 'VvqYQ98FjO0iYpKHgu91fw', 'st...   \n",
      "\n",
      "                   action action_time_segment  \\\n",
      "0  rQ1t0zD_TBTqCF06By_UgA           afternoon   \n",
      "1  XsvxRd2u8iRD_S50ZJ5-QQ           afternoon   \n",
      "2  sYgyAxvuDP1799oiGXqE_A             evening   \n",
      "\n",
      "                                        user_profile  \\\n",
      "0  {'review_count': 33, 'average_stars': 4.06, 'f...   \n",
      "1  {'review_count': 33, 'average_stars': 4.06, 'f...   \n",
      "2  {'review_count': 33, 'average_stars': 4.06, 'f...   \n",
      "\n",
      "                                  business_checkin  \\\n",
      "0   {'morning': 0, 'afternoon': 18, 'evening': 14}   \n",
      "1  {'morning': 9, 'afternoon': 21, 'evening': 148}   \n",
      "2  {'morning': 0, 'afternoon': 68, 'evening': 167}   \n",
      "\n",
      "                                 business_categories  reward  \\\n",
      "0                 [Sandwiches, Restaurants, Italian]       1   \n",
      "1  [Italian, Sports Bars, Nightlife, Bars, Restau...       1   \n",
      "2                    [Fast Food, Restaurants, Pizza]       1   \n",
      "\n",
      "                                          next_state  \n",
      "0  [{'business_id': 'gpYBhnTk4KzvvH83TsZiQg', 'st...  \n",
      "1  [{'business_id': 'VvqYQ98FjO0iYpKHgu91fw', 'st...  \n",
      "2  [{'business_id': 'rAe-1HU5Z-DuUXEbzASXDA', 'st...  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(subset)\n",
    "\n",
    "print(train_df.columns)\n",
    "print(train_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdb7f2",
   "metadata": {},
   "source": [
    "### STEP 2: Build User-Item Matrix for Biclustering\n",
    "\n",
    "Create a binary matrix where rows are users and columns are businesses. A `1` indicates the user has recently interacted with that business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647223e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item matrix shape: (3749, 61386)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract user_id and associated business_ids from 'state'\n",
    "user_history = defaultdict(set)\n",
    "\n",
    "for row in train_df.itertuples():\n",
    "    try:\n",
    "        user_id = row.user_id\n",
    "        for interaction in row.state:\n",
    "            business_id = interaction.get(\"business_id\")\n",
    "            if business_id:\n",
    "                user_history[user_id].add(business_id)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# 1.2 Build binary user-item matrix\n",
    "all_users = list(user_history.keys())\n",
    "all_businesses = list({b for bs in user_history.values() for b in bs})\n",
    "\n",
    "user_item_matrix = pd.DataFrame(0, index=all_users, columns=all_businesses)\n",
    "\n",
    "for user, businesses in user_history.items():\n",
    "    user_item_matrix.loc[user, list(businesses)] = 1\n",
    "\n",
    "print(\"User-item matrix shape:\", user_item_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f8330",
   "metadata": {},
   "source": [
    "In step 1.2:\n",
    "1. This creates a **binary interaction matrix**: \n",
    "- rows = Users\n",
    "- columns = business\n",
    "\n",
    "This matrix is used for **biclustering** in the next step:\n",
    "- It enables the model to group similar users and similar businesses.\n",
    "- Helps reduce the size of the Q-table by abstracting to **clusters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174e2b9",
   "metadata": {},
   "source": [
    "### STEP 3: Apply Biclustering\n",
    "\n",
    "Transforms the raw user-item interactions into **clustered states**, dramatically simplifying the Q-learning state space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8345e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biclustering complete.\n",
      "User clusters: 50\n",
      "Business clusters: 50\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 50  # tune this\n",
    "model = SpectralBiclustering(n_clusters=n_clusters, method='log', random_state=42)\n",
    "model.fit(user_item_matrix)\n",
    "\n",
    "# Map user and business IDs to their cluster assignments\n",
    "user_clusters = dict(zip(user_item_matrix.index, model.row_labels_))\n",
    "business_clusters = dict(zip(user_item_matrix.columns, model.column_labels_))\n",
    "\n",
    "print(\"Biclustering complete.\")\n",
    "print(f\"User clusters: {len(set(model.row_labels_))}\")\n",
    "print(f\"Business clusters: {len(set(model.column_labels_))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3debea",
   "metadata": {},
   "source": [
    "`SpectralBiclustering` finds **co-clusters**:\n",
    "\n",
    "- Groups of users that behave similarly.\n",
    "- Groups of businesses that are frequently co-interacted with.\n",
    "\n",
    "`n_clusters=50`:Get 50 user clusters and 50 business clusters.\n",
    "\n",
    "`alpha`: Controls how much new information overrides old Q-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c50b4f",
   "metadata": {},
   "source": [
    "### STEP 4: Define the Q-Learning Agent\n",
    "\n",
    "Create a class that learns a value function `Q(state, action)` to recommend items based on learned behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6382f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_by_cluster = defaultdict(list)\n",
    "for b_id, cluster_id in business_clusters.items():\n",
    "    businesses_by_cluster[cluster_id].append(b_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9a197",
   "metadata": {},
   "source": [
    "For each business ID `(b_id)` and its corresponding cluster ID `(cluster_id)`:\n",
    "\n",
    "Appending that business to a list of businesses assigned to that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5576a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ClusteredQLearningAgent:\n",
    "    def __init__(self, actions, alpha=0.1, gamma=0.95, epsilon=0.1):\n",
    "        self.q_table = defaultdict(lambda: defaultdict(float))  # Q[state][action] = value\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.actions = actions  # all business_ids\n",
    "\n",
    "    def get_state(self, user_id, time_segment):\n",
    "        user_cluster = user_clusters.get(user_id, -1)\n",
    "        return (user_cluster, time_segment)\n",
    "\n",
    "    #def choose_action(self, state):\n",
    "    #    q_vals = self.q_table[state]\n",
    "    #    if q_vals:\n",
    "    #        return max(q_vals, key=q_vals.get)\n",
    "    #    return random.choice(self.actions)\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        q_vals = self.q_table[state]\n",
    "        if q_vals:\n",
    "            return max(q_vals, key=q_vals.get)\n",
    "\n",
    "    # fallback: recommend from user’s business cluster\n",
    "        user_cluster_id = state[0]\n",
    "        cluster_businesses = businesses_by_cluster.get(user_cluster_id)\n",
    "\n",
    "        if cluster_businesses:\n",
    "            return random.choice(cluster_businesses)\n",
    "\n",
    "        return random.choice(self.actions)\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        max_q_next = max(self.q_table[next_state].values(), default=0.0)\n",
    "        current_q = self.q_table[state][action]\n",
    "        self.q_table[state][action] = current_q + self.alpha * (reward + self.gamma * max_q_next - current_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02090200",
   "metadata": {},
   "source": [
    "Uses **cluster IDs** to define states.\n",
    "\n",
    "Implements **Q-learning** with:\n",
    "\n",
    "- `choose_action`: balances exploration and exploitation.\n",
    "\n",
    "- `update`: updates Q-values after observing reward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffeddd",
   "metadata": {},
   "source": [
    "### STEP 5: Train the Agent on  Dataset\n",
    "\n",
    "Use each (user, action, reward, next_state) tuple from `train_df` to train the Q-table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2226660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training complete. Q-table has 150 states.\n"
     ]
    }
   ],
   "source": [
    "# Get all known business IDs from the matrix\n",
    "all_business_ids = list(user_item_matrix.columns)\n",
    "\n",
    "# Instantiate agent\n",
    "agent = ClusteredQLearningAgent(actions=all_business_ids)\n",
    "\n",
    "# Train using actual user actions from the dataset\n",
    "for row in train_df.itertuples():\n",
    "    try:\n",
    "        user_id = row.user_id\n",
    "        business_id = row.action  # actual clicked/engaged business\n",
    "        reward = row.reward\n",
    "        time_segment = row.action_time_segment  # e.g. 'morning', 'evening'\n",
    "\n",
    "        state = agent.get_state(user_id, time_segment)\n",
    "        next_state = agent.get_state(user_id, time_segment)  # simplified\n",
    "\n",
    "        agent.update(state, business_id, reward, next_state)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Training error:\", e)\n",
    "        continue\n",
    "\n",
    "print(f\" Training complete. Q-table has {len(agent.q_table)} states.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59155782",
   "metadata": {},
   "source": [
    "- `row.action`: This is the actual business ID the user interacted with → this is your action in Q-learning.\n",
    "\n",
    "- `reward`: Binary reward based on whether the interaction was positive.\n",
    "\n",
    "- `time_segment`: Time context (e.g., \"evening\", \"morning\") — part of your state abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157e28a",
   "metadata": {},
   "source": [
    "## Evaluate the Q-learning Agent on `rl_dataset_test.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac11ab8",
   "metadata": {},
   "source": [
    "Measure how well the trained agent recommends businesses to users using unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24acbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first 100000 entries efficiently\n",
    "test_data = stream_first_n_json_objects(\"rl_dataset_test.json\", 50000 )\n",
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf83be",
   "metadata": {},
   "source": [
    " ### Step 2: Evaluate the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d281b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Businesses seen during training\n",
    "known_businesses = set(train_df[\"action\"])  # All valid actions for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c19e66",
   "metadata": {},
   "source": [
    "Only want to recommend businesses that were present in the training set.\n",
    "\n",
    "Otherwise, the agent might suggest businesses it’s never learned about (which is unfair and unhelpful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fce9ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training loop\n",
    "from collections import Counter\n",
    "\n",
    "business_counter = Counter(train_df[\"action\"])\n",
    "most_popular_businesses = [b for b, _ in business_counter.most_common()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01d4c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [03:15<00:00, 255.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-50 Evaluation complete on 50000 test samples\n",
      "Precision@50: 0.018\n",
      "Recall@50:    0.018\n",
      "F1 Score@50:  0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Precompute fallback action space (optional, for speed)\n",
    "businesses_by_cluster = defaultdict(list)\n",
    "for b_id, cluster_id in business_clusters.items():\n",
    "    businesses_by_cluster[cluster_id].append(b_id)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "TOP_K = 50\n",
    "total_predictions = 0\n",
    "total_relevant = 0\n",
    "hits = 0\n",
    "rewards = []\n",
    "state_cache = {}\n",
    "\n",
    "# Evaluate\n",
    "for entry in tqdm(test_data):\n",
    "    try:\n",
    "        user_id = entry[\"user_id\"]\n",
    "\n",
    "        # Fix if action is a nested dict\n",
    "        true_business_id = entry[\"action\"] if isinstance(entry[\"action\"], str) else entry[\"action\"][\"business_id\"]\n",
    "\n",
    "        # Also fix if time segment is nested\n",
    "        time_segment = entry.get(\"action_time_segment\", None)\n",
    "        if not time_segment and isinstance(entry[\"action\"], dict):\n",
    "            time_segment = entry[\"action\"].get(\"action_time_segment\", \"unknown\")\n",
    "\n",
    "        reward = entry[\"reward\"]\n",
    "\n",
    "        # Cache user-time state\n",
    "        key = (user_id, time_segment)\n",
    "        if key not in state_cache:\n",
    "            state_cache[key] = agent.get_state(user_id, time_segment)\n",
    "        state = state_cache[key]\n",
    "\n",
    "        # Main recommendation logic\n",
    "        #already_seen = user_history.get(user_id, set())\n",
    "        q_vals = agent.q_table[state]\n",
    "        q_vals = agent.q_table[state]\n",
    "        if q_vals:\n",
    "            top_k_businesses = sorted(q_vals.items(), key=lambda x: -x[1])\n",
    "            recommended_businesses = [\n",
    "                b for b, _ in top_k_businesses if b in known_businesses\n",
    "            ][:TOP_K]\n",
    "\n",
    "        else:\n",
    "            # Fallback: recommend from same cluster, filtered to known businesses\n",
    "            user_cluster = state[0]\n",
    "            fallback_businesses = businesses_by_cluster.get(user_cluster, agent.actions)\n",
    "            filtered_fallbacks = [b for b in fallback_businesses if b in known_businesses]\n",
    "\n",
    "            if filtered_fallbacks:\n",
    "                recommended_businesses = random.sample(filtered_fallbacks, min(TOP_K, len(filtered_fallbacks)))\n",
    "            else:\n",
    "                recommended_businesses = most_popular_businesses[:TOP_K]\n",
    "\n",
    "        total_predictions += 1\n",
    "        total_relevant += 1\n",
    "\n",
    "        if true_business_id in recommended_businesses:\n",
    "            hits += 1\n",
    "            rewards.append(reward)\n",
    "        else:\n",
    "            rewards.append(0)\n",
    "\n",
    "    except Exception as e:\n",
    "        continue  # skip any faulty records\n",
    "\n",
    "# Compute metrics\n",
    "precision_at_k = hits / total_predictions if total_predictions > 0 else 0\n",
    "recall_at_k = hits / total_relevant if total_relevant > 0 else 0\n",
    "f1_at_k = (\n",
    "    2 * precision_at_k * recall_at_k / (precision_at_k + recall_at_k)\n",
    "    if (precision_at_k + recall_at_k) > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"\\nTop-{TOP_K} Evaluation complete on {total_predictions} test samples\")\n",
    "print(f\"Precision@{TOP_K}: {precision_at_k:.3f}\")\n",
    "print(f\"Recall@{TOP_K}:    {recall_at_k:.3f}\")\n",
    "print(f\"F1 Score@{TOP_K}:  {f1_at_k:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
